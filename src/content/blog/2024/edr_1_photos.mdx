---
title: "Adventures in EDR, Part 1: Displaying EDR Photos in iOS 17"
pubDatetime: 2024-01-13T19:00:00.000Z
description: >
  The state of EDR images today, and how to render and display them in iOS 17 with SwiftUI.
featured: true
draft: false
tags:
  - ios
  - edr
  - hdr
  - photos
  - swift
  - swiftui
---

import BlogVideoPlayer from "@components/BlogVideoPlayer.svelte";

If you have a recent iPhone and open Photos.app, you'll probably notice that
some images seem to 'pop'.
Look closer, and you may realize that the rest of the UI now looks grey:

<BlogVideoPlayer
  baseUrl="/assets/blog/2024/edr/edr_photos/"
  source={[
    { src: "h265.10.mp4", type: 'video/mp4; codecs="hev1.2.1.H120.b0"' },
    { src:  "h265.8.mp4", type: 'video/mp4; codecs="hev1.1.1.H120.b0"' },
    { src:  "av1.10.mp4", type: 'video/mp4; codecs="av01.0.08M.10"' },
    { src:   "av1.8.mp4", type: 'video/mp4; codecs="av01.0.31M.08"' },
    { src: "h264.10.mp4", type: 'video/mp4; codecs="avc1.6e0028"' },
    { src:  "h264.8.mp4", type: 'video/mp4; codecs="avc1.640028"' },
  ]}
  poster="poster.jpg"
  description="Video of the Photos app showing a photo of a sunset, with the sun getting brighter as EDR kicks in."
  aspectRatio={16 / 9}
/>

This is **extended dynamic range**; Apple's method of seamlessly displaying HDR
content alongside SDR content.

In building my camera app [Composure Camera](https://composure.rioogino.com/),
I wanted to do the same thing, and ended up doing a deep dive into the world of EDR.

In part 1, I cover how to display and render EDR photos in SwiftUI and UIKit
while in [part 2](/posts/2024/edr_2_metal), I cover EDR rendering with Metal
and go deep into color spaces and transfer functions.

## Gain Map HDR

Gain map HDR is a backwards-compatible way of supporting EDR in photos by
embedding a separate *gain map* image alongside the primary SDR image. iPhones have
supported this since 2020, and this is the most common form of EDR photo you will
see today.

The gain map is a lower-resolution, single-channel bitmap which is used to adjust
the brightness of an image. Software that does not support this will simply ignore
it, ensuring that the photo can be rendered in SDR without any issues.

This technique effectively increases the bitdepth of the image, reducing
the banding that would otherwise make displaying 8-bit images -- the maximum
bitdepth supported by JPEG -- in HDR unusable.

Since DNG (RAW) files embed JPEG previews and ISO HDR images cannot be supported
by JPEG files, any RAW or ProRAW files you take will use this technique for the
foreseeable future.

Additionally, even normal HEIC files captured by Apple devices use this type of
EDR image. Thus, if you want to support EDR for photos taken on iPhones, you
will have to implement support for this.

Starting in iOS 17, Apple has finally provided an
[easy](https://gist.github.com/kiding/fa4876ab4ddc797e3f18c71b3c2eeb3a)
API to render these images.

As described at the very end of [this WWDC session](https://developer.apple.com/videos/play/wwdc2023/10181/?time=1080),
we can now use:

```swift
guard let ciImage = CIImage(
  data: data,
  options: [.expandToHDR: true]
) else { return }

// And now render to a bitmap
guard let cgImage = ciContext.createCGImage(
  ciImage,
  from: ciImage.extent,
  // Half the size of .RGBA16. Don't use 8-bit formats
  format: .RGB10,
  // Can use any extended, extendedLinear, PQ, or HLG format
  colorSpace: .init(name: CGColorSpace.itur_2100_HLG)
) else { return }
```

in order to render image data to an HDR texture. I go into more detail on color
spaces in part 2.

This process is more expensive than the standard `ciContext.createCGImage(_:from)`
call, even if the image does not contain a gain map. On a 12MP ProRAW JPEG preview
(which contains a gain map), it took ~30 ms compared to 3 ms to render on an
iPhone Xs.

To detect if the image contains an HDR gain map, we can check the image's
EXIF metadata to determine if it has a
[headroom value](https://developer.apple.com/documentation/appkit/images_and_pdf/applying_apple_hdr_effect_to_your_photos).
This metadata is embedded in Apple's [undocumented](https://github.com/anteo/edit-hdr-gamma)
EXIF manufacturer tags, so it seems unlikely that this format will see use in
non-Apple devices.

Note that reading the EXIF metadata with `CGImageSourceCreateWithData` and
`CGImageSourceCopyPropertiesAtIndex` also takes a few milliseconds.

Once rendered, simply wrap the `CGImage` in an `UIImage` before displaying it
in SwiftUI with the new iOS 17 View modifier:

```swift
Image(uiImage: uiImage)
  .allowedDynamicRange(.high)
```

UIKit also has an equivalent property which can be set to enable EDR:
`UIImageView.preferredImageDynamicRange`.

Apple is [standardizing](https://developer.apple.com/documentation/appkit/images_and_pdf/applying_apple_hdr_effect_to_your_photos)
this under [ISO/NP 21496-1](https://www.iso.org/standard/86775.html).
However, **Adobe also has its own separate, incompatible gain map
[specification](https://helpx.adobe.com/nz/camera-raw/using/gain-map.html)**
which is used in Lightroom for HDR exports.
From their [support page](https://helpx.adobe.com/nz/lightroom-cc/using/hdr-ios.html),
it seems that only Chrome desktop can view these images -- as of iOS 17, Core
Image does not support these.
However, as the specification is open and well-documented, it seems feasible
for an individual to implement this.

## ISO HDR

[ISO HDR](https://developer.apple.com/videos/play/wwdc2023/10181/)
is a newer method devised by Apple. Currently being standardized as
[ISO/TS 22028-5:2023](https://www.iso.org/standard/86775.html), this gets rid
of the separate gain map and natively encodes the image in HDR.

It requires the use of an HDR *transfer function*:
[hybrid log-gamma](https://en.wikipedia.org/wiki/Hybrid_log%E2%80%93gamma) or
[perceptual quantization](https://en.wikipedia.org/wiki/Perceptual_quantizer)
and a wide colorspace: the BT.2100 (or equivalently, BT.2020) color primaries.
There are also a bunch of metadata requirements which I don't understand.

It also requires a minimum bitdepth of 10 bits, ruling out JPEGs support.
Additionally, Apple devices currently capture images in Display P3, not BT.2100.
As such, until Apple switches to using this color space for the camera, this
method will likely not see widespread use.

Apple's [HDR sample app](https://developer.apple.com/documentation/uikit/images_and_pdf/supporting_hdr_images_in_your_app)
saves images in the BT.2100 color space, but I haven't otherwise encountered
any images which use this color space.

However, the same is not true of video -- HDR videos captured on iPhone, as well as any
professional HDR content (movies, TV etc.) you see will be using BT.2100 with
PQ/HLG. As such, it is not a stretch that Apple will switch photos to using this
color space in the future, especially as Photos.app can already convert images to
JPEG when sharing for compatibility.

{/*
This would, however, lead to the loss of backwards compatibility: if you have
tried to play HDR video on non-Apple devices or older software, it is likely that
you have seen these videos play looking washed out or plain wrong: the software
*must* support the color space and transfer function to display the content
correctly.
*/}

Supporting these images in iOS 17 is easier than supporting tone-mapped HDR:
just use `UIImage(data: data)`, or even just `Image(name: )` alongside the
aforementioned `.allowedDynamicRange` modifier.

## RAW

RAW images (both Bayer RAW and ProRAW) can be rendered using
[`CIRAWFilter`](https://developer.apple.com/videos/play/wwdc2021/10160/?time=1108),
which was introduced back in 2021.

Rendering these images in EDR requires only a few minor modifications:

```swift
guard let rawFilter = CIRAWFilter(imageData: data, identifierHint: uniformTypeIdentifier) else {
    return nil
}

// https://developer.apple.com/videos/play/wwdc2021/10160/?time=1108
// Optional
rawFilter.baselineExposure      = 0.0
rawFilter.shadowBias            = 0.0
rawFilter.boostAmount           = 0.0
rawFilter.localToneMapAmount    = 0.0

// Must be true for EDR
rawFilter.isGamutMappingEnabled = true
rawFilter.extendedDynamicRangeAmount = 1.0

let colorSpace = CGColorSpace(CGColorSpace.displayP3_PQ)!
let context = CIContext(options: [.outputColorSpace: colorSpace])

guard let outputImage = rawFilter.outputImage,
      let cgImage = context.createCGImage(
        outputImage,
        from: outputImage.extent,
        format: RGB10,
        colorSpace: colorSpace
      ) else { return }
```

`isGamutMappingEnabled` must be true - when false, the image gets rendered in
linear space and is limited to SDR.

Before realizing this, I spent a long time attempting to render to a Metal texture,
and created a Metal EDR pipeline to do so - something I cover in part 2.
This ended up not working due to performance issues - for whatever reason,
`CIContext.render(_:to:commandBuffer:bounds:colorSpace:)` would sometimes take
upwards of 30 second to render a 48MP ProRAW MAX image.

I picked the `displayP3_PQ` color space in this example and although it seems to work,
I'm not exactly sure why: in the documentation for
[`allowedDynamicRange(_:)`](https://developer.apple.com/documentation/swiftui/image/alloweddynamicrange(_:)),
it implies that the image must have an HDR color space and that `BT.2100` is
the only one.

If `displayP3_PQ` didn't work, I would have assumed that EDR support for RAW
(as well as gain map HDR, which also works with P3) is achieved by
converting the color space to BT.2100 and embedding the necessary metadata
for EDR.

In Apple's [WDDC session](https://developer.apple.com/videos/play/wwdc2023/10181/)
and a 2021 [presentation](https://www.color.org/hdr/07-Nicolas_Bonnier.pdf) on
ISO HDR, it states that BT.2100 is a requirement. As such, it seems like Apple is
ignoring its own specification and is suporting HDR with Display P3 images.

## Conclusion

Although iOS 17 finally introduces native support for displaying EDR images,
we are still in the early days of this technology, with three separate ways of
supporting EDR. However, given that trillions of iPhone photos have been captured
with Apple's HDR gain map technique, this will be the primary type of EDR you should
support today.

Adobe's version, which has an open specification and lack of proprietary EXIF tags,
will likely see more widespread adoption in the future. As for ISO HDR,
supporting it is 'free' in iOS 17 with SwiftUI/UIKit, but it will likely take
many years before we see any significant adoption.

Next up in [part 2](/posts/2024/edr_2_metal), I cover my misadventures in EDR rendering in Metal.
